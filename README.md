# Serega2780_infra

Serega2780 Infra repository

Ansible-3

Проект из ДЗ 9 переработан под использование ролей;
Созданы роли для:
 базы данных MongoDB;
 приложения Puma;
 деплоя Reddit;
Протестирована работа ролей со статическим окружением;
Создано несколько окрудений - prod и stage;
Для каждого окружения определены group_vars;
Протестирована работа со статическим окружением, group_vars для каждого окружения отдельно;
Установлена и настроена community-role jdauphant.nginx для внедрения обратного прокси; 
Проверена работоспособность приложения на tcp 80;
Использованы возможности ansible vault для шифрования файлов учетных записей пользователей и их расшифровки "на лету" во время выполнения play-book;


Выполнено задание со *.
Для удобства демонстрации разницы между статическим и динамическим окружением созданы отдельные плейбуки:
  site_dynamic.yml;
  app_dynamic.yml;
  db_dynamic.yml;
  deploy_dynamic.yml;
Поскольку при использовании скрипта gce.py домашней папкой окружения со всеми доступными переменными становится папка, в которой расположены gce.py и gce.ini, эти файлы должны быть продублированы в папках ./environments/stage и ./environments/prod;

По умолчанию dynamic inventory видит только файл ./environments/stage(prod)/group_vars/all (для всех хостов), что не всегда удобно.
Поэтому, для корректного обнаружения group_vars при динамическом окружении файлы с описанием переменных по хостам
./environments/stage(prod)/group_vars/app
./environments/stage(prod)/group_vars/db

должны быть переименованы в
./environments/stage(prod)/group_vars/tag_reddit-app
./environments/stage(prod)/group_vars/tag_reddit-db,
соответственно.

Для удобства демонстрации новые файлы просто добавлены, без переименования статических.

Для запуска статического окружения необходимо убедиться. что в файле ansible.cfg в поле inventory прописан путь до нужного окружение: stage или prod. Далее, находясь в папке ansible следует выполнить команду:

ansible-playbook ./playbooks/site.yml

В случае использования динамического оокружения путь переменной inventory в ansible.cfg можно закомментировать, а в качесве параметра -i команды ansible-playbook явно указать путь до gce.py, расположенном в нужном окружении -  stage или prod:

ansible-playbook -i environments/stage/gce.py ./playbooks/site_dynamic.yml - для stage,
ansible-playbook -i environments/prod/gce.py ./playbooks/site_dynamic.yml - для prod.

Таким образом, мы явно указываем какое именно окружение хотим создать и подтягиваем соответствующие переменные.



Ansible-2

Протестирован режим "один playbook - один сценарий" с переменными, handlers;
Протестирован режим "один playbook - несколько сценариев";
Протестирован режим "несколько playbook";
Provisioning в Packer с режима sh script изменен на Ansible playbook.

Выполнено задание со *.
Установлен/настроен gce.py;
Изменен ansible.cfg так, чтобы использовать динамический inventory из gce.py, а не статический из inventory.yml;
Созданы новые плейбуки site_dynamic.yml, db_dynamic.yml, app_dynamic.yml, deploy_dynamic.yml. Они используют имена виртуальных машин, полученных с помощью gce.py. Таким образом, теперь при пересоздании инфраструктуры с помощью Terraform и, как следствие, изменении внешних ip адресов, пропала необходимость каждый раз прописывать новые адреса в статический inventory.yml. Обращение плейбука происходит по имени машины, которое не меняется при перезапусках.


Ansible-1

Поскольку командой rm -rf ~/reddit удалили каталог reddit, при следующем запуске 
ansible-playbook clone.yml произошел повторный запуск task Clone repo,
чтобы заново создать этот каталог. Поэтому статус changed: [appserver]

Установлен Ansible. Поскольку на ВМ в GC по умолчанию установлен python 3, пришлось в inventory файл добавить строку инициализации
с правльным путем до python на удаленной ВМ. Этот вариант не описывался в методичке к ДЗ ansible_python_interpreter= \
/usr/bin/python3

Выполнены все примеры из ДЗ.

Terraform-2

поднят стенд из двух ВМ, созданных из разных образов
протестировано наличие на них соответствующего ПО mongodb и ruby
код инфтраструктуры разбит по модулям
затем по веткам: stage и prod
создавались buckets


Terraform-1

установлен terraform
создан файл main.tf со всеми настройками
определены и настроены input и output переменные
с помощью terraform развернула ВМ из образа, на ней автоматически запещен сервис puma
через web протестирован функционал сервиса puma
=======

Bastion

bastion_IP = 35.189.195.32
=======
cloud-testapp
testapp_IP = 35.233.40.230
testapp_port = 9292

установлен и настроен gcloud
с помощью gcloud создана ВМ
написаны скрипты для установки Ruby, Mongodb, а также скрипт деплоя приложения


=======
bastion_IP = 35.189.195.32
someinternalhost_IP = 10.132.0.3
